{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f61b3981-4b2d-4fc5-9b0e-a3ead6ace57e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/simon.nagy@hiflylabs.com/.bundle/dbxSandbox/dbxSandbox/sandboxProject/includeFiles/Classroom-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba9cbef1-cc35-47fa-83f7-02999527676c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = spark.read.format(\"delta\").load(events_path).select(\"user_id\", col(\"event_timestamp\").alias(\"timestamp\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bb1cc6e-eb91-4270-b027-d6c35a63b949",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Datetime built in functions\n",
    "- add_months() returns the date that is numMonths after startDate\n",
    "- current_timestamp() returns the current timestamp at the start of the query evaluation\n",
    "- date_format() converts the date/timestamp/string to value of string in the format specified by the date format given by the second args.\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0089e47-527a-42d4-8d23-62187b72aa15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "timestamp_df = df.withColumn(\"timestamp\", (col(\"timestamp\")/1e6).cast(\"timestamp\"))\n",
    "display(timestamp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aa4681d-e5bc-42dc-a278-7ef88275eeb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format\n",
    "\n",
    "formatted_df = (timestamp_df\n",
    "                .withColumn(\"date string\", date_format(\"timestamp\", \"MMMM dd, yyyy\"))\n",
    "                .withColumn(\"time string\", date_format(\"timestamp\", \"HH:mm:ss.SSSS\"))\n",
    "                )\n",
    "\n",
    "display(formatted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7d469d7-1ab7-44a7-be00-8186bcb49589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofweek, minute, second\n",
    "\n",
    "datetime_df = (timestamp_df\n",
    "    .withColumn(\"year\", year(col(\"timestamp\")))\n",
    "    .withColumn(\"month\", month(col(\"timestamp\")))\n",
    "    .withColumn(\"dayofweek\", dayofweek(col(\"timestamp\")))\n",
    "    .withColumn(\"minute\", minute(col(\"timestamp\")))\n",
    "    .withColumn(\"second\", second(col(\"timestamp\")))\n",
    ")\n",
    "\n",
    "display(datetime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5aaed531-fd02-4f2b-ad12-b31d6eba8b1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Manipulating datetimes\n",
    "- `date_add()` <= adding days to an already existing date>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1530277e-1042-4fba-b73d-77929bb0c114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "classroom_cleanup()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Functions-2-datetimes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
